{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch NER Bilstm CRF Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchtext\n",
    "from torchtext.data import Field, BucketIterator\n",
    "from torchtext.datasets import UDPOS\n",
    "from torchcrf import CRF\n",
    "\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "from sklearn.metrics import f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_en = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_en(text):\n",
    "    return [token.text for token in spacy_en.tokenizer(text.lower())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = Field(\n",
    "    sequential=True, \n",
    "    tokenize=tokenizer_en,\n",
    "#     init_token=\"<sos>\",\n",
    "    eos_token=\"<eos>\",\n",
    "#     batch_first=True,\n",
    "    lower=True\n",
    ")\n",
    "LABELS = Field(\n",
    "    sequential=True, \n",
    "#     init_token=\"<sos>\",\n",
    "    eos_token=\"<eos>\",\n",
    "#     batch_first=True,\n",
    "    is_target=True\n",
    ")\n",
    "# PTB_LABELS = Field(\n",
    "#     sequential=True, \n",
    "#     init_token=\"<sos>\",\n",
    "#     eos_token=\"<eos>\",\n",
    "# #     batch_first=True,\n",
    "#     is_target=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12543, 2002, 2077)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data, validation_data, test_data = UDPOS.splits(fields=((\"text\", TEXT), (\"labels\", LABELS), (None, None)))\n",
    "len(training_data), len(validation_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence : al - zaman : american forces killed shaikh abdullah al - ani , the preacher at the mosque in the town of qaim , near the syrian border .\n",
      "pos : PROPN PUNCT PROPN PUNCT ADJ NOUN VERB PROPN PROPN PROPN PUNCT PROPN PUNCT DET NOUN ADP DET NOUN ADP DET NOUN ADP PROPN PUNCT ADP DET ADJ NOUN PUNCT\n"
     ]
    }
   ],
   "source": [
    "example = vars(training_data.examples[0])\n",
    "# example\n",
    "print(\"sentence : {}\".format(\" \".join(example[\"text\"])))\n",
    "print(\"pos : {}\".format(\" \".join(example[\"labels\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16656, 20)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.build_vocab(training_data, vectors=\"glove.6B.100d\")\n",
    "LABELS.build_vocab(training_data)\n",
    "# PTB_LABELS.build_vocab(training_data)\n",
    "\n",
    "len(TEXT.vocab), len(LABELS.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98, 65, 63)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_iterator, val_iterator, test_iterator = BucketIterator.splits(\n",
    "    (training_data, validation_data, test_data),\n",
    "    batch_sizes=(128, 32, 32), device=device\n",
    ")\n",
    "len(training_iterator), len(test_iterator), len(val_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in training_iterator:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([49, 128])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<eos>', 'NOUN')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABELS.vocab.itos[2], LABELS.vocab.itos[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_size = len(TEXT.vocab)\n",
    "# embedding_dim = 10\n",
    "# hidden_dim = 5\n",
    "# tagset_size = len(LABELS.vocab)\n",
    "\n",
    "# embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "# lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "# linear_layer = nn.Linear(hidden_dim, tagset_size)\n",
    "# crf_layer = CRF(tagset_size)\n",
    "\n",
    "# print(\"Input X shape is {}\".format(batch.text.shape))\n",
    "\n",
    "# embedded = embedding(batch.text)\n",
    "# print(\"Shape of embedded is {}\".format(embedded.shape))\n",
    "\n",
    "# lstm_out , (_, _) = lstm(embedded)\n",
    "# print(\"Shape of lstm out is {}\".format(lstm_out.shape))\n",
    "\n",
    "# emmissions = linear_layer(lstm_out)\n",
    "# print(\"Emmission output shape is {}\".format(emmissions.shape))\n",
    "\n",
    "# loss = crf_layer(emmissions, batch.labels)\n",
    "# print(loss.item())\n",
    "\n",
    "# crf_out = crf_layer.decode(emmissions)\n",
    "# crf_out\n",
    "\n",
    "# torch.tensor(crf_out, dtype=torch.long, device=device).permute(1, 0).shape\n",
    "\n",
    "# LABELS.vocab.itos[15], LABELS.vocab.itos[6], LABELS.vocab.itos[14], LABELS.vocab.itos[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLstm_Crf(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, num_layers, bidirectional):\n",
    "        super(BiLstm_Crf, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        self.lstm = nn.LSTM(input_size=self.embedding_dim, hidden_size=self.hidden_dim, num_layers=self.num_layers, bidirectional=self.bidirectional,\n",
    "                           dropout=0.5)\n",
    "        \n",
    "        self.dropout_layer = nn.Dropout(0.5)\n",
    "        self.linear = nn.Linear(self.hidden_dim, self.output_dim)\n",
    "        \n",
    "        self.crf_layer = CRF(self.output_dim)\n",
    "        self.inference = False\n",
    "        \n",
    "    def forward(self, inp, labels):\n",
    "        # inp = [seq_len, batch_size]\n",
    "        # labels = [seq_len, batch_size]\n",
    "             \n",
    "        embedded = self.dropout_layer(self.embedding(inp))\n",
    "        # embedded = [seq_len, batch_size, embedding_dim]\n",
    "        \n",
    "        outputs, (hidden, cell) = self.lstm(embedded)\n",
    "        # outputs = [seq_len, batch_size, 1 * hidden_size]\n",
    "        \n",
    "        out = self.linear(outputs)\n",
    "        # out = [seq_len, batch_size, output_dim]\n",
    "        \n",
    "        if self.inference is False:\n",
    "            loss = self.crf_layer(out, labels) * torch.tensor(-1, device=device)\n",
    "            return loss \n",
    "        else:\n",
    "            loss = self.crf_layer(out, labels) * torch.tensor(-1, device=device)\n",
    "            out = self.crf_layer.decode(out)\n",
    "            out = torch.tensor(out, dtype=torch.long, device=device).permute(1, 0)\n",
    "            # out = [seq_len, batch_size]\n",
    "            return out, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, device=None):\n",
    "    model.train()\n",
    "    model.inference = False\n",
    "    \n",
    "    epoch_loss = 0.0 \n",
    "    \n",
    "    for batch in tqdm(iterator):\n",
    "        inp = batch.text\n",
    "        target = batch.labels\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss = model(inp, target)\n",
    "        # crf loss\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, device=None):\n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0.0\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    model.inference = True\n",
    "    for batch in tqdm(iterator):\n",
    "        inp = batch.text\n",
    "        target = batch.labels\n",
    "                \n",
    "        out, loss = model(inp, target)\n",
    "        # out = [seq_len, batch_size]\n",
    "        # crf loss\n",
    "        \n",
    "        predictions.extend(out.contiguous().view(-1).cpu().tolist())\n",
    "        true_labels.extend(target.contiguous().view(-1).cpu().tolist())\n",
    "                \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    f1 = f1_score(true_labels, predictions, average=\"macro\")\n",
    "        \n",
    "    return epoch_loss / len(iterator), f1\n",
    "\n",
    "def number_of_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BiLstm_Crf(\n",
    "    vocab_size=len(TEXT.vocab), \n",
    "    embedding_dim=100, hidden_dim=512, \n",
    "    output_dim=len(LABELS.vocab), \n",
    "    num_layers=2, bidirectional=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.2634,  0.0742, -0.1081,  ..., -0.2977, -0.5655,  0.5218],\n",
       "        [ 0.4244,  0.6004, -0.1528,  ...,  0.2536, -0.4969,  0.8964]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding.weight.data.copy_(TEXT.vocab.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5035020"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.CrossEntropyLoss(ignore_index=LABELS.vocab.stoi[\"<pad>\"])\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "# criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:14<00:00,  6.02it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 50.49it/s] \n",
      "  0%|          | 0/98 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Train Loss: 6329.186 | Val. Loss: 624.330\n",
      "Val. F1 Score is : 0.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:13<00:00,  7.70it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 51.77it/s] \n",
      "  1%|          | 1/98 [00:00<00:15,  6.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Train Loss: 2378.740 | Val. Loss: 288.909\n",
      "Val. F1 Score is : 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:13<00:00,  7.69it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 50.46it/s] \n",
      "  1%|          | 1/98 [00:00<00:13,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Train Loss: 1453.874 | Val. Loss: 210.056\n",
      "Val. F1 Score is : 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:13<00:00,  7.33it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 50.97it/s] \n",
      "  1%|          | 1/98 [00:00<00:16,  5.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Train Loss: 1111.871 | Val. Loss: 170.241\n",
      "Val. F1 Score is : 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:13<00:00,  8.08it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 50.47it/s] \n",
      "  1%|          | 1/98 [00:00<00:13,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Train Loss: 924.792 | Val. Loss: 153.603\n",
      "Val. F1 Score is : 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:13<00:00,  8.27it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 30.26it/s] \n",
      "  1%|          | 1/98 [00:00<00:12,  7.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06 | Train Loss: 807.012 | Val. Loss: 142.830\n",
      "Val. F1 Score is : 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:13<00:00,  7.45it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 41.46it/s]\n",
      "  1%|          | 1/98 [00:00<00:15,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07 | Train Loss: 725.779 | Val. Loss: 134.676\n",
      "Val. F1 Score is : 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:14<00:00,  7.22it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 49.49it/s] \n",
      "  1%|          | 1/98 [00:00<00:16,  6.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08 | Train Loss: 659.371 | Val. Loss: 128.561\n",
      "Val. F1 Score is : 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:13<00:00,  6.77it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 50.24it/s] \n",
      "  1%|          | 1/98 [00:00<00:13,  7.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09 | Train Loss: 600.591 | Val. Loss: 123.838\n",
      "Val. F1 Score is : 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:13<00:00,  7.92it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 50.14it/s] \n",
      "  1%|          | 1/98 [00:00<00:15,  6.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Train Loss: 559.757 | Val. Loss: 119.059\n",
      "Val. F1 Score is : 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:13<00:00,  7.17it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 51.25it/s] \n",
      "  1%|          | 1/98 [00:00<00:16,  6.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | Train Loss: 522.958 | Val. Loss: 118.265\n",
      "Val. F1 Score is : 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:13<00:00,  7.34it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 50.44it/s] \n",
      "  0%|          | 0/98 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 | Train Loss: 623.533 | Val. Loss: 117.596\n",
      "Val. F1 Score is : 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:13<00:00,  7.90it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 50.16it/s] \n",
      "  1%|          | 1/98 [00:00<00:13,  7.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 | Train Loss: 495.269 | Val. Loss: 117.992\n",
      "Val. F1 Score is : 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:13<00:00,  7.39it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 29.14it/s] \n",
      "  1%|          | 1/98 [00:00<00:17,  5.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 | Train Loss: 457.182 | Val. Loss: 113.168\n",
      "Val. F1 Score is : 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:13<00:00,  8.30it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 51.06it/s] \n",
      "  1%|          | 1/98 [00:00<00:15,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 | Train Loss: 435.451 | Val. Loss: 111.487\n",
      "Val. F1 Score is : 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:13<00:00,  7.30it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 51.91it/s] \n",
      "  1%|          | 1/98 [00:00<00:17,  5.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 | Train Loss: 412.324 | Val. Loss: 110.190\n",
      "Val. F1 Score is : 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:13<00:00,  7.21it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 51.54it/s] \n",
      "  1%|          | 1/98 [00:00<00:17,  5.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 | Train Loss: 396.053 | Val. Loss: 110.351\n",
      "Val. F1 Score is : 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:13<00:00,  6.76it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 49.65it/s] \n",
      "  1%|          | 1/98 [00:00<00:17,  5.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 | Train Loss: 380.987 | Val. Loss: 106.906\n",
      "Val. F1 Score is : 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:13<00:00,  7.11it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 51.07it/s] \n",
      "  1%|          | 1/98 [00:00<00:17,  5.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 | Train Loss: 364.136 | Val. Loss: 108.069\n",
      "Val. F1 Score is : 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:13<00:00,  8.37it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 52.51it/s] \n",
      "  0%|          | 0/98 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 | Train Loss: 351.528 | Val. Loss: 111.736\n",
      "Val. F1 Score is : 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:13<00:00,  6.38it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 51.02it/s] \n",
      "  1%|          | 1/98 [00:00<00:12,  7.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21 | Train Loss: 339.629 | Val. Loss: 105.796\n",
      "Val. F1 Score is : 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:14<00:00,  7.08it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 52.69it/s] \n",
      "  1%|          | 1/98 [00:00<00:14,  6.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22 | Train Loss: 329.845 | Val. Loss: 117.291\n",
      "Val. F1 Score is : 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:14<00:00,  7.17it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 23.69it/s] \n",
      "  1%|          | 1/98 [00:00<00:13,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23 | Train Loss: 355.828 | Val. Loss: 106.356\n",
      "Val. F1 Score is : 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:14<00:00,  7.01it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 41.37it/s]\n",
      "  1%|          | 1/98 [00:00<00:14,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24 | Train Loss: 324.808 | Val. Loss: 106.892\n",
      "Val. F1 Score is : 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:13<00:00,  7.55it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 50.04it/s] \n",
      "  1%|          | 1/98 [00:00<00:14,  6.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25 | Train Loss: 309.856 | Val. Loss: 109.088\n",
      "Val. F1 Score is : 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:13<00:00,  6.15it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 50.90it/s] \n",
      "  0%|          | 0/98 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26 | Train Loss: 298.249 | Val. Loss: 107.244\n",
      "Val. F1 Score is : 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:14<00:00,  7.39it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 50.05it/s] \n",
      "  1%|          | 1/98 [00:00<00:16,  6.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27 | Train Loss: 291.703 | Val. Loss: 106.167\n",
      "Val. F1 Score is : 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:13<00:00,  7.12it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 51.67it/s] \n",
      "  1%|          | 1/98 [00:00<00:15,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28 | Train Loss: 283.729 | Val. Loss: 108.248\n",
      "Val. F1 Score is : 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:14<00:00,  6.78it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 50.60it/s] \n",
      "  1%|          | 1/98 [00:00<00:17,  5.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29 | Train Loss: 274.447 | Val. Loss: 104.800\n",
      "Val. F1 Score is : 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:13<00:00,  7.01it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 49.44it/s] \n",
      "  0%|          | 0/98 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30 | Train Loss: 268.928 | Val. Loss: 105.215\n",
      "Val. F1 Score is : 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:14<00:00,  6.68it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 50.62it/s] \n",
      "  1%|          | 1/98 [00:00<00:16,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31 | Train Loss: 258.888 | Val. Loss: 110.216\n",
      "Val. F1 Score is : 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:13<00:00,  7.46it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 51.78it/s] \n",
      "  1%|          | 1/98 [00:00<00:12,  7.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32 | Train Loss: 251.500 | Val. Loss: 104.715\n",
      "Val. F1 Score is : 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:12<00:00,  7.95it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 51.82it/s] \n",
      "  1%|          | 1/98 [00:00<00:13,  7.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33 | Train Loss: 246.687 | Val. Loss: 103.616\n",
      "Val. F1 Score is : 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:13<00:00,  6.28it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 49.14it/s] \n",
      "  0%|          | 0/98 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34 | Train Loss: 238.663 | Val. Loss: 106.623\n",
      "Val. F1 Score is : 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:13<00:00,  7.56it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 50.50it/s] \n",
      "  0%|          | 0/98 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35 | Train Loss: 232.118 | Val. Loss: 107.709\n",
      "Val. F1 Score is : 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:14<00:00,  7.00it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 50.26it/s] \n",
      "  1%|          | 1/98 [00:00<00:16,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36 | Train Loss: 227.759 | Val. Loss: 109.898\n",
      "Val. F1 Score is : 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:13<00:00,  7.36it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 49.12it/s] \n",
      "  0%|          | 0/98 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37 | Train Loss: 221.966 | Val. Loss: 108.908\n",
      "Val. F1 Score is : 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:14<00:00,  6.69it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 29.66it/s] \n",
      "  0%|          | 0/98 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38 | Train Loss: 216.278 | Val. Loss: 112.235\n",
      "Val. F1 Score is : 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:13<00:00,  7.03it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 51.49it/s] \n",
      "  1%|          | 1/98 [00:00<00:16,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39 | Train Loss: 211.867 | Val. Loss: 110.520\n",
      "Val. F1 Score is : 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:13<00:00,  6.67it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 50.39it/s] \n",
      "  1%|          | 1/98 [00:00<00:14,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40 | Train Loss: 205.519 | Val. Loss: 108.792\n",
      "Val. F1 Score is : 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:13<00:00,  6.73it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 50.49it/s] \n",
      "  1%|          | 1/98 [00:00<00:15,  6.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41 | Train Loss: 202.767 | Val. Loss: 110.941\n",
      "Val. F1 Score is : 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:13<00:00,  7.59it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 50.85it/s] \n",
      "  1%|          | 1/98 [00:00<00:13,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42 | Train Loss: 195.179 | Val. Loss: 112.639\n",
      "Val. F1 Score is : 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:13<00:00,  7.77it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 50.91it/s] \n",
      "  1%|          | 1/98 [00:00<00:16,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43 | Train Loss: 188.874 | Val. Loss: 112.556\n",
      "Val. F1 Score is : 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:13<00:00,  6.84it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 50.40it/s] \n",
      "  1%|          | 1/98 [00:00<00:13,  7.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44 | Train Loss: 184.949 | Val. Loss: 109.875\n",
      "Val. F1 Score is : 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:13<00:00,  7.41it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 52.52it/s] \n",
      "  1%|          | 1/98 [00:00<00:15,  6.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45 | Train Loss: 181.702 | Val. Loss: 113.805\n",
      "Val. F1 Score is : 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:13<00:00,  7.54it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 51.22it/s] \n",
      "  1%|          | 1/98 [00:00<00:14,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46 | Train Loss: 175.624 | Val. Loss: 113.627\n",
      "Val. F1 Score is : 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:13<00:00,  6.85it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 52.21it/s] \n",
      "  0%|          | 0/98 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47 | Train Loss: 171.796 | Val. Loss: 114.558\n",
      "Val. F1 Score is : 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:13<00:00,  7.22it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 50.73it/s] \n",
      "  1%|          | 1/98 [00:00<00:13,  7.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48 | Train Loss: 167.204 | Val. Loss: 115.348\n",
      "Val. F1 Score is : 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:14<00:00,  7.39it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 49.89it/s] \n",
      "  1%|          | 1/98 [00:00<00:13,  7.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49 | Train Loss: 162.263 | Val. Loss: 117.863\n",
      "Val. F1 Score is : 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:13<00:00,  7.26it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 50.88it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50 | Train Loss: 157.926 | Val. Loss: 121.868\n",
      "Val. F1 Score is : 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 50\n",
    "model.inference = False\n",
    "VAL_LOSS = 1e10\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss = train(model, training_iterator, optimizer)\n",
    "    val_loss, val_f1 = evaluate(model, val_iterator)\n",
    "    \n",
    "    if VAL_LOSS > val_loss:\n",
    "        VAL_LOSS = val_loss\n",
    "        torch.save(model.state_dict(), 'bilstm-ner-crf-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Val. Loss: {val_loss:.3f}')\n",
    "    print(f'Val. F1 Score is : {val_f1:.2f}')\n",
    "    torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('bilstm-ner-crf-model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text = <unk> <eos>\n",
      "Output = X <eos>\n",
      "Truth = PROPN <eos>\n",
      "\n",
      "text = julie <eos>\n",
      "Output = PROPN <eos>\n",
      "Truth = PROPN <eos>\n",
      "\n",
      "text = professional <eos>\n",
      "Output = ADJ <eos>\n",
      "Truth = ADJ <eos>\n",
      "\n",
      "text = thanks . <eos>\n",
      "Output = NOUN PUNCT <eos>\n",
      "Truth = NOUN PUNCT <eos>\n",
      "\n",
      "text = <unk> <unk> <eos>\n",
      "Output = PROPN PROPN <eos>\n",
      "Truth = PROPN PROPN <eos>\n",
      "\n",
      "text = bill <unk> <eos>\n",
      "Output = PROPN PROPN <eos>\n",
      "Truth = PROPN PROPN <eos>\n",
      "\n",
      "text = <unk> ! <eos>\n",
      "Output = NOUN PUNCT <eos>\n",
      "Truth = ADJ PUNCT <eos>\n",
      "\n",
      "text = <unk> <unk> am <eos>\n",
      "Output = PROPN PROPN AUX <eos>\n",
      "Truth = NUM NUM NOUN <eos>\n",
      "\n",
      "text = absolutely free . <eos>\n",
      "Output = ADV ADJ PUNCT <eos>\n",
      "Truth = ADV ADJ PUNCT <eos>\n",
      "\n",
      "text = <unk> - <unk> <eos>\n",
      "Output = NOUN PUNCT PROPN <eos>\n",
      "Truth = NUM PUNCT NOUN <eos>\n",
      "\n",
      "text = thanks from bill <eos>\n",
      "Output = NOUN ADP PROPN <eos>\n",
      "Truth = NOUN ADP PROPN <eos>\n",
      "\n",
      "text = <unk> was awesome . <eos>\n",
      "Output = NOUN AUX ADJ PUNCT <eos>\n",
      "Truth = PROPN AUX ADJ PUNCT <eos>\n",
      "\n",
      "text = mix it all up <eos>\n",
      "Output = NOUN PRON DET ADP <eos>\n",
      "Truth = VERB PRON DET ADP <eos>\n",
      "\n",
      "text = good local bike shop <eos>\n",
      "Output = ADJ ADJ NOUN NOUN <eos>\n",
      "Truth = ADJ ADJ NOUN NOUN <eos>\n",
      "\n",
      "text = are you enjoying houston ? <eos>\n",
      "Output = AUX PRON VERB PROPN PUNCT <eos>\n",
      "Truth = AUX PRON VERB PROPN PUNCT <eos>\n",
      "\n",
      "text = who se better looking ? <eos>\n",
      "Output = PRON AUX ADV VERB PUNCT <eos>\n",
      "Truth = PRON VERB ADV VERB PUNCT <eos>\n",
      "\n",
      "text = gets busy so come early <eos>\n",
      "Output = VERB ADJ ADV VERB ADV <eos>\n",
      "Truth = VERB ADJ ADV VERB ADV <eos>\n",
      "\n",
      "text = power be where power lies . <eos>\n",
      "Output = NOUN AUX ADV NOUN NOUN PUNCT <eos>\n",
      "Truth = NOUN VERB ADV NOUN VERB PUNCT <eos>\n",
      "\n",
      "text = they <unk> up too much space <eos>\n",
      "Output = PRON VERB ADV ADV ADJ NOUN <eos>\n",
      "Truth = PRON VERB ADP ADV ADJ NOUN <eos>\n",
      "\n",
      "text = beware they will rip u off <eos>\n",
      "Output = VERB PRON AUX VERB PRON ADP <eos>\n",
      "Truth = VERB PRON AUX VERB PRON ADP <eos>\n",
      "\n",
      "text = i highly recommend his shop . <eos>\n",
      "Output = PRON ADV VERB PRON NOUN PUNCT <eos>\n",
      "Truth = PRON ADV VERB PRON NOUN PUNCT <eos>\n",
      "\n",
      "text = please let me know you preference . <eos>\n",
      "Output = INTJ VERB PRON VERB PRON NOUN PUNCT <eos>\n",
      "Truth = INTJ VERB PRON VERB PRON NOUN PUNCT <eos>\n",
      "\n",
      "text = my cat s name is <unk> . <eos>\n",
      "Output = PRON NOUN PART NOUN AUX ADJ PUNCT <eos>\n",
      "Truth = PRON NOUN PART NOUN AUX PROPN PUNCT <eos>\n",
      "\n",
      "text = how much better does it get ?! <eos>\n",
      "Output = ADV ADV ADV AUX PRON VERB PUNCT <eos>\n",
      "Truth = ADV ADV ADJ AUX PRON VERB PUNCT <eos>\n",
      "\n",
      "text = we will meeting rod 's office eb <unk> <eos>\n",
      "Output = PRON AUX VERB PROPN PART PROPN PROPN PROPN <eos>\n",
      "Truth = PRON AUX VERB PROPN PART NOUN PROPN NUM <eos>\n",
      "\n",
      "text = are they just making these places up ? <eos>\n",
      "Output = AUX PRON ADV VERB DET NOUN ADV PUNCT <eos>\n",
      "Truth = AUX PRON ADV VERB DET NOUN ADP PUNCT <eos>\n",
      "\n",
      "text = they 've always been timely and inexpensive . <eos>\n",
      "Output = PRON AUX ADV AUX ADJ CCONJ ADJ PUNCT <eos>\n",
      "Truth = PRON AUX ADV AUX ADJ CCONJ ADJ PUNCT <eos>\n",
      "\n",
      "text = i was thinking <unk> 's at around 5 . <eos>\n",
      "Output = PRON AUX VERB PROPN PART ADV ADV NUM PUNCT <eos>\n",
      "Truth = PRON AUX VERB PROPN PART ADP ADV NUM PUNCT <eos>\n",
      "\n",
      "text = anyone know of any <unk> training in <unk> ? <eos>\n",
      "Output = PRON VERB ADP DET NOUN NOUN ADP PROPN PUNCT <eos>\n",
      "Truth = PRON VERB ADP DET PROPN NOUN ADP PROPN PUNCT <eos>\n",
      "\n",
      "text = the experience with every department has been great . <eos>\n",
      "Output = DET NOUN ADP DET NOUN AUX AUX ADJ PUNCT <eos>\n",
      "Truth = DET NOUN ADP DET NOUN AUX AUX ADJ PUNCT <eos>\n",
      "\n",
      "text = now , people wonder if google can even survive . <eos>\n",
      "Output = ADV PUNCT NOUN VERB SCONJ PROPN AUX ADV VERB PUNCT <eos>\n",
      "Truth = ADV PUNCT NOUN VERB SCONJ PROPN AUX ADV VERB PUNCT <eos>\n",
      "\n",
      "text = hope they do n't call the police and arrest you <eos>\n",
      "Output = VERB PRON AUX PART VERB DET NOUN CCONJ NOUN PRON <eos>\n",
      "Truth = VERB PRON AUX PART VERB DET NOUN CCONJ VERB PRON <eos>\n",
      "\n",
      "text = hard to get into though because of road construction . <eos>\n",
      "Output = ADJ PART VERB ADP ADV SCONJ ADP NOUN NOUN PUNCT <eos>\n",
      "Truth = ADJ PART VERB ADP ADV ADP ADP NOUN NOUN PUNCT <eos>\n",
      "\n",
      "text = i am in the process of reviewing your special provisions . <eos>\n",
      "Output = PRON AUX ADP DET NOUN SCONJ VERB PRON ADJ NOUN PUNCT <eos>\n",
      "Truth = PRON AUX ADP DET NOUN SCONJ VERB PRON ADJ NOUN PUNCT <eos>\n",
      "\n",
      "text = so now i do not bother with them at all . <eos>\n",
      "Output = ADV ADV PRON AUX PART VERB ADP PRON ADV ADV PUNCT <eos>\n",
      "Truth = ADV ADV PRON AUX PART VERB ADP PRON ADV ADV PUNCT <eos>\n",
      "\n",
      "text = you are n't going in for the wedding until sunday now ? <eos>\n",
      "Output = PRON AUX PART VERB ADV ADP DET NOUN ADP PROPN ADV PUNCT <eos>\n",
      "Truth = PRON AUX PART VERB ADV ADP DET NOUN ADP PROPN ADV PUNCT <eos>\n",
      "\n",
      "text = yes storage for your <unk> is still available at gare montparnasse . <eos>\n",
      "Output = INTJ NOUN ADP PRON NOUN AUX ADV ADJ ADP PROPN PROPN PUNCT <eos>\n",
      "Truth = INTJ NOUN ADP PRON NOUN AUX ADV ADJ ADP PROPN PROPN PUNCT <eos>\n",
      "\n",
      "text = glad i called before i arrived with my box to ship . <eos>\n",
      "Output = ADJ PRON VERB SCONJ PRON VERB ADP PRON NOUN ADP NOUN PUNCT <eos>\n",
      "Truth = ADJ PRON VERB SCONJ PRON VERB ADP PRON NOUN PART VERB PUNCT <eos>\n",
      "\n",
      "text = cats react to the treatment they receive , they are not toys . <eos>\n",
      "Output = NOUN VERB ADP DET NOUN PRON VERB PUNCT PRON AUX PART NOUN PUNCT <eos>\n",
      "Truth = NOUN VERB ADP DET NOUN PRON VERB PUNCT PRON AUX PART NOUN PUNCT <eos>\n",
      "\n",
      "text = compare to last decade this university is gaining more prestige in international level <eos>\n",
      "Output = VERB ADP ADJ NOUN DET NOUN AUX VERB ADJ NOUN ADP ADJ NOUN <eos>\n",
      "Truth = VERB ADP ADJ NOUN DET PROPN AUX VERB ADJ NOUN ADP ADJ NOUN <eos>\n",
      "\n",
      "text = i have already submitted my resume and cover letter right after the talk . <eos>\n",
      "Output = PRON VERB ADV VERB PRON NOUN CCONJ NOUN NOUN ADV ADP DET NOUN PUNCT <eos>\n",
      "Truth = PRON AUX ADV VERB PRON NOUN CCONJ NOUN NOUN ADV ADP DET NOUN PUNCT <eos>\n",
      "\n",
      "text = great spot to kick back for a cup of joe and a snack . <eos>\n",
      "Output = ADJ NOUN PART VERB ADV ADP DET NOUN ADP PROPN CCONJ DET NOUN PUNCT <eos>\n",
      "Truth = ADJ NOUN PART VERB ADV ADP DET NOUN ADP NOUN CCONJ DET NOUN PUNCT <eos>\n",
      "\n",
      "text = i am expecting to pay something in the $ <unk> to $ 5,000 range . <eos>\n",
      "Output = PRON AUX VERB PART VERB PRON ADP DET SYM NUM ADP SYM NUM NOUN PUNCT <eos>\n",
      "Truth = PRON AUX VERB PART VERB PRON ADP DET SYM NUM ADP SYM NUM NOUN PUNCT <eos>\n",
      "\n",
      "text = cheap hotel rome - thanks for finding us a hotel at the last minute . <eos>\n",
      "Output = ADJ NOUN PROPN PUNCT NOUN ADP VERB PRON DET NOUN ADP DET ADJ NOUN PUNCT <eos>\n",
      "Truth = PROPN PROPN PROPN PUNCT NOUN SCONJ VERB PRON DET NOUN ADP DET ADJ NOUN PUNCT <eos>\n",
      "\n",
      "text = oil companies evacuated offshore facilities as the storm 's progress kept global markets on <unk> . <eos>\n",
      "Output = NOUN NOUN VERB ADJ NOUN ADP DET NOUN PART NOUN VERB ADJ NOUN ADP NOUN PUNCT <eos>\n",
      "Truth = NOUN NOUN VERB ADJ NOUN SCONJ DET NOUN PART NOUN VERB ADJ NOUN ADP NOUN PUNCT <eos>\n",
      "\n",
      "text = but sometimes , of course , when <unk> happens after x it is because of x . <eos>\n",
      "Output = CCONJ ADV PUNCT ADP ADV PUNCT ADV VERB VERB ADP SYM PRON VERB SCONJ ADP NOUN PUNCT <eos>\n",
      "Truth = CCONJ ADV PUNCT ADV ADV PUNCT ADV NOUN VERB ADP NOUN PRON VERB ADP ADP NOUN PUNCT <eos>\n",
      "\n",
      "text = we had a great stay , your service was excellent and we will use you again ! <eos>\n",
      "Output = PRON VERB DET ADJ NOUN PUNCT PRON NOUN AUX ADJ CCONJ PRON AUX VERB PRON ADV PUNCT <eos>\n",
      "Truth = PRON VERB DET ADJ NOUN PUNCT PRON NOUN AUX ADJ CCONJ PRON AUX VERB PRON ADV PUNCT <eos>\n",
      "\n",
      "text = it s illegal to sell stolen property , even if you do n't know it s stolen . <eos>\n",
      "Output = PRON AUX ADJ PART VERB VERB NOUN PUNCT ADV SCONJ PRON AUX PART VERB PRON AUX VERB PUNCT <eos>\n",
      "Truth = PRON AUX ADJ PART VERB VERB NOUN PUNCT ADV SCONJ PRON AUX PART VERB PRON AUX VERB PUNCT <eos>\n",
      "\n",
      "text = if you would prefer to settle the taxes with a personal check , we can distribute gross shares . <eos>\n",
      "Output = SCONJ PRON AUX VERB PART VERB DET NOUN ADP DET ADJ NOUN PUNCT PRON AUX VERB ADJ NOUN PUNCT <eos>\n",
      "Truth = SCONJ PRON AUX VERB PART VERB DET NOUN ADP DET ADJ NOUN PUNCT PRON AUX VERB ADJ NOUN PUNCT <eos>\n",
      "\n",
      "text = that was the name of his \" <unk> \" -- <unk> - written by <unk> karen hughes in 1999 . <eos>\n",
      "Output = PRON AUX DET NOUN ADP PRON PUNCT NOUN PUNCT PUNCT NOUN PUNCT VERB ADP PROPN PROPN PROPN ADP NUM PUNCT <eos>\n",
      "Truth = PRON AUX DET NOUN ADP PRON PUNCT NOUN PUNCT PUNCT NOUN PUNCT VERB ADP NOUN PROPN PROPN ADP NUM PUNCT <eos>\n",
      "\n",
      "text = in the eastern city of <unk> , guerrillas detonated a car bomb outside a police station , killing several people . <eos>\n",
      "Output = ADP DET ADJ NOUN ADP PROPN PUNCT NOUN VERB DET NOUN NOUN ADP DET NOUN NOUN PUNCT VERB ADJ NOUN PUNCT <eos>\n",
      "Truth = ADP DET ADJ NOUN ADP PROPN PUNCT NOUN VERB DET NOUN NOUN ADP DET NOUN NOUN PUNCT VERB ADJ NOUN PUNCT <eos>\n",
      "\n",
      "text = the american - arab discrimination committee is <unk> condoleeza rice and donald rumsfeld , charging that they <unk> the <unk> efforts . <eos>\n",
      "Output = DET ADJ PUNCT ADJ NOUN NOUN AUX VERB PROPN PROPN CCONJ PROPN PROPN PUNCT VERB SCONJ PRON VERB DET NOUN NOUN PUNCT <eos>\n",
      "Truth = DET PROPN PUNCT PROPN PROPN PROPN AUX VERB PROPN PROPN CCONJ PROPN PROPN PUNCT VERB SCONJ PRON VERB DET NOUN NOUN PUNCT <eos>\n",
      "\n",
      "text = i just want to extend a big \" welcome ! \" to <unk> <unk> fisher who joined me at google this week . <eos>\n",
      "Output = PRON ADV VERB PART VERB DET ADJ PUNCT ADJ PUNCT PUNCT ADP PROPN PROPN PROPN PRON VERB PRON ADP PROPN DET NOUN PUNCT <eos>\n",
      "Truth = PRON ADV VERB PART VERB DET ADJ PUNCT NOUN PUNCT PUNCT ADP PROPN PROPN PROPN PRON VERB PRON ADP PROPN DET NOUN PUNCT <eos>\n",
      "\n",
      "text = the atmosphere is the best .. italian music , <unk> , helpful and friendly staff ... and the food is beautiful too ! <eos> <pad>\n",
      "Output = DET NOUN AUX DET ADJ PUNCT ADJ NOUN PUNCT NOUN PUNCT ADJ CCONJ ADJ NOUN PUNCT CCONJ DET NOUN AUX ADJ ADV PUNCT <eos> <pad>\n",
      "Truth = DET NOUN AUX DET ADJ PUNCT ADJ NOUN PUNCT NOUN PUNCT ADJ CCONJ ADJ NOUN PUNCT CCONJ DET NOUN AUX ADJ ADV PUNCT <eos> <pad>\n",
      "\n",
      "text = [ am at a conference and ca n't blog much right now but will try to catch up the next couple of days . ] <eos>\n",
      "Output = PUNCT AUX ADP DET NOUN CCONJ AUX PART VERB ADV ADV ADV CCONJ AUX VERB PART VERB ADP DET ADJ NOUN ADP NOUN PUNCT PUNCT <eos>\n",
      "Truth = PUNCT AUX ADP DET NOUN CCONJ AUX PART VERB ADV ADV ADV CCONJ AUX VERB PART VERB ADP DET ADJ NOUN ADP NOUN PUNCT PUNCT <eos>\n",
      "\n",
      "text = \" the problem is not with the palestinian resistance groups but with israel 's scheme to destroy the palestinians ' infrastructure , \" <unk> said . <eos>\n",
      "Output = PUNCT DET NOUN AUX PART ADP DET ADJ NOUN NOUN CCONJ ADP PROPN PART NOUN PART VERB DET PROPN PUNCT NOUN PUNCT PUNCT NOUN VERB PUNCT <eos>\n",
      "Truth = PUNCT DET NOUN AUX PART ADP DET ADJ NOUN NOUN CCONJ ADP PROPN PART NOUN PART VERB DET PROPN PART NOUN PUNCT PUNCT PROPN VERB PUNCT <eos>\n",
      "\n",
      "text = i was ready to buy a new jacket , a new <unk> and a couple of your overpriced belts and i walked out because of your obvious <unk> <eos>\n",
      "Output = PRON AUX ADJ PART VERB DET ADJ NOUN PUNCT DET ADJ NOUN CCONJ DET NOUN ADP PRON ADJ NOUN CCONJ PRON VERB ADV SCONJ ADP PRON ADJ NOUN <eos>\n",
      "Truth = PRON AUX ADJ PART VERB DET ADJ NOUN PUNCT DET ADJ NOUN CCONJ DET NOUN ADP PRON ADJ NOUN CCONJ PRON VERB ADV ADP ADP PRON ADJ NOUN <eos>\n",
      "\n",
      "text = i had a dead battery last week and called this company since they were the <unk> they had very quick service for a monday morning , thanks again guys . <eos> <pad>\n",
      "Output = PRON VERB DET ADJ NOUN ADJ NOUN CCONJ VERB DET NOUN SCONJ PRON AUX DET NOUN PRON VERB ADV ADJ NOUN ADP DET PROPN NOUN PUNCT NOUN ADV NOUN PUNCT <eos> <pad>\n",
      "Truth = PRON VERB DET ADJ NOUN ADJ NOUN CCONJ VERB DET NOUN SCONJ PRON AUX DET ADJ PRON VERB ADV ADJ NOUN ADP DET PROPN NOUN PUNCT NOUN ADV NOUN PUNCT <eos> <pad>\n",
      "\n",
      "text = i have wifi at my house , but that s just at my house ... is there any way i can buy some card to make the <unk> itself have wifi ? <eos>\n",
      "Output = PRON VERB NOUN ADP PRON NOUN PUNCT CCONJ PRON AUX ADV ADP PRON NOUN PUNCT AUX PRON DET NOUN PRON AUX VERB DET NOUN PART VERB DET NOUN PRON VERB NOUN PUNCT <eos>\n",
      "Truth = PRON VERB NOUN ADP PRON NOUN PUNCT CCONJ PRON VERB ADV ADP PRON NOUN PUNCT VERB PRON DET NOUN PRON AUX VERB DET NOUN PART VERB DET PROPN PRON VERB NOUN PUNCT <eos>\n",
      "\n",
      "text = radical shiite cleric <unk> al - sadr said the attack was \" criminal \" and that \" the <unk> have left only one choice for the arabs , that of fighting and jihad \" . <eos>\n",
      "Output = ADJ ADJ NOUN VERB PROPN PUNCT PROPN VERB DET NOUN AUX PUNCT ADJ PUNCT CCONJ SCONJ PUNCT DET NOUN AUX VERB ADV NUM NOUN ADP DET PROPN PUNCT PRON ADP NOUN CCONJ NOUN PUNCT PUNCT <eos>\n",
      "Truth = ADJ ADJ NOUN PROPN PROPN PUNCT PROPN VERB DET NOUN AUX PUNCT ADJ PUNCT CCONJ SCONJ PUNCT DET PROPN AUX VERB ADV NUM NOUN ADP DET PROPN PUNCT PRON ADP NOUN CCONJ NOUN PUNCT PUNCT <eos>\n",
      "\n",
      "text = i am deadly serious , i really do get sexual <unk> from even hearing of torture of animals , now some people may call me a <unk> or a <unk> but i ca nt help my true feelings . <eos>\n",
      "Output = PRON AUX ADJ ADJ PUNCT PRON ADV AUX VERB ADJ NOUN ADP ADV VERB ADP NOUN ADP NOUN PUNCT ADV DET NOUN AUX VERB PRON DET NOUN CCONJ DET NOUN CCONJ PRON AUX PART VERB PRON ADJ NOUN PUNCT <eos>\n",
      "Truth = PRON AUX ADV ADJ PUNCT PRON ADV AUX VERB ADJ NOUN SCONJ ADV VERB ADP NOUN ADP NOUN PUNCT ADV DET NOUN AUX VERB PRON DET NOUN CCONJ DET NOUN CCONJ PRON AUX PART VERB PRON ADJ NOUN PUNCT <eos>\n",
      "\n",
      "text = i do n't think they ban if the <unk> are n't offensive and you should make them not noticeable at the time of the interview but once you got the job there nothing they can really say if so you have a sue / case against them <eos> <pad>\n",
      "Output = PRON AUX PART VERB PRON VERB SCONJ DET NOUN AUX PART ADJ CCONJ PRON AUX VERB PRON ADV ADJ ADP DET NOUN ADP DET NOUN CCONJ SCONJ PRON VERB DET NOUN ADV PRON PRON AUX ADV VERB SCONJ ADV PRON VERB DET PROPN PUNCT NOUN ADP PRON <eos> <pad>\n",
      "Truth = PRON AUX PART VERB PRON VERB SCONJ DET NOUN AUX PART ADJ CCONJ PRON AUX VERB PRON ADV ADJ ADP DET NOUN ADP DET NOUN CCONJ SCONJ PRON VERB DET NOUN PRON PRON PRON AUX ADV VERB SCONJ ADV PRON VERB DET NOUN PUNCT NOUN ADP PRON <eos> <pad>\n",
      "\n",
      "text = the complaint , filed with the united states department of housing and urban development , accuses <unk> of <unk> a 2003 enforcement agreement entered into between former st. thomas housing development residents , the city of new orleans , <unk> , and the u.s. department of housing and urban development during the hope vi <unk> of st. thomas , now known as river garden . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Output = DET NOUN PUNCT VERB ADP DET PROPN PROPN PROPN ADP PROPN CCONJ PROPN PROPN PUNCT VERB NOUN ADP PROPN DET NUM NOUN NOUN VERB ADP ADP ADJ PROPN PROPN PROPN PROPN PROPN PUNCT DET NOUN ADP PROPN PROPN PUNCT PROPN PUNCT CCONJ DET PROPN PROPN ADP PROPN CCONJ ADJ NOUN ADP DET PROPN PROPN NOUN ADP PROPN PROPN PUNCT ADV VERB ADP PROPN PROPN PUNCT <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Truth = DET NOUN PUNCT VERB ADP DET PROPN PROPN PROPN ADP PROPN CCONJ PROPN PROPN PUNCT VERB PROPN SCONJ VERB DET NUM NOUN NOUN VERB ADP ADP ADJ PROPN PROPN PROPN PROPN NOUN PUNCT DET PROPN ADP PROPN PROPN PUNCT PROPN PUNCT CCONJ DET PROPN PROPN ADP PROPN CCONJ PROPN PROPN ADP DET PROPN PROPN NOUN ADP PROPN PROPN PUNCT ADV VERB ADP PROPN PROPN PUNCT <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(val_iterator):\n",
    "    model.eval()\n",
    "    model.inference = True\n",
    "    inp = batch.text[:, 1].unsqueeze(1)\n",
    "    targ = batch.labels[:, 1]\n",
    "#     print(inp.tolist())\n",
    "    outputs, loss = model(inp, targ.unsqueeze(1))\n",
    "    # outputs = [seq_len, batch_size]\n",
    "#     print(outputs.view(-1).tolist())\n",
    "    print(\"text = {}\".format(\" \".join([TEXT.vocab.itos[w] for w in list(inp.view(-1).tolist())])))\n",
    "    sentence = \" \".join([LABELS.vocab.itos[w] for w in list(outputs.view(-1).tolist())])\n",
    "    print(\"Output = {}\".format(sentence))\n",
    "    print(\"Truth = {}\".format(\" \".join([LABELS.vocab.itos[w] for w in list(targ.view(-1).tolist())])))\n",
    "    print()\n",
    "    if i == 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, batch in enumerate(val_iterator):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"\n",
    "    Keeps track of most recent, average, sum, and count of a metric.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.inference = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ones_like() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype), but expected one of:\n * (Tensor input, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (Tensor input, bool requires_grad)\n      didn't match because some of the keywords were incorrect: dtype\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-748f27866d1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/users-workspace/kuldeep.singh/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-e4ed0e985b8c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp, labels)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrf_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrf_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/users-workspace/kuldeep.singh/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/users-workspace/kuldeep.singh/miniconda3/lib/python3.7/site-packages/torchcrf/__init__.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, emissions, tags, mask, reduction)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'invalid reduction: {reduction}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_first\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: ones_like() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype), but expected one of:\n * (Tensor input, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (Tensor input, bool requires_grad)\n      didn't match because some of the keywords were incorrect: dtype\n"
     ]
    }
   ],
   "source": [
    "outputs = model(batch.text[:, 1].unsqueeze(1), None)\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1s = AverageMeter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 2]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.labels[:, 1].to(\"cpu\").tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 2]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.view(-1).to(\"cpu\").tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/users-workspace/kuldeep.singh/miniconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/data/users-workspace/kuldeep.singh/miniconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(batch.labels[:, 1].to(\"cpu\").tolist(), outputs.view(-1).to(\"cpu\").tolist(), average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0.])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1s.update(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1s.val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
